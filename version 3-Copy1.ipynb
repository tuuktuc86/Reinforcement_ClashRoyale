{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "970e56a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import collections\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pyautogui as pag\n",
    "import PIL\n",
    "import torchvision.transforms as transforms\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0d1d1fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e94ef1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DQN 모델 정의\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DQN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(nn.Conv2d(3, 16, 3, stride=2, padding=1),\n",
    "                                   nn.BatchNorm2d(16),\n",
    "                                   nn.ReLU(inplace=True))\n",
    "        self.conv2 = nn.Sequential(nn.Conv2d(16, 64, 3, stride=2, padding=1),\n",
    "                                   nn.BatchNorm2d(64),\n",
    "                                   nn.ReLU(inplace=True))\n",
    "        self.conv3 = nn.Sequential(nn.Conv2d(64, 256, 3, stride=2, padding=1),\n",
    "                                   nn.BatchNorm2d(256),\n",
    "                                   nn.ReLU(inplace=True))\n",
    "        self.actor_linear = nn.Sequential(nn.Linear(1851392, 256),\n",
    "                                          nn.ReLU(inplace=True),\n",
    "                                          nn.Linear(256,10))\n",
    "\n",
    "    def forward(self, x): #각 action에 대한 가치를 softmax를 거쳐서 확률로 출력\n",
    "        x = self.conv1(x)\n",
    "        print(f\"1 / {time.time()}\")\n",
    "        x = self.conv2(x)\n",
    "        print(f\"2 / {time.time()}\")\n",
    "        x = self.conv3(x)\n",
    "        print(f\"3 / {time.time()}\")\n",
    "        x = self.actor_linear(x.reshape(x.size(0), -1))\n",
    "        print(f\"4 / {time.time()}\")\n",
    "        return x\n",
    "    \n",
    "    def sample_action(self, obs, epsilon):\n",
    "        out = self.forward(obs)\n",
    "        coin = random.random()\n",
    "        if coin < epsilon:\n",
    "            return random.randint(0, 10)\n",
    "        else:\n",
    "            return out.argmax().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d0ffc38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_list = [[2720, 550], [2860, 550], [3000, 550], [2720 ,660], [2860, 660], [3000, 660], [2765, 900], [2855, 900], [2950, 900], [3055, 900], [-1, -1]]\n",
    "#action list 정의. action list는 6개의 필드 위치와 4개의 카드 위치 그리고 한개의 아무것도 안하는 리워드를 주었다.\n",
    "action_list_name = {0:'left top', 1:'center top', 2:'right top', 3:'right bottom', 4:'center bottom', 5:'center right', 6:'card 1', 7:'card 2', 8:'card 3', 9:'card 4', 10:'rest action'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1b130d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ENV():\n",
    "    def __init__(self):\n",
    "        #screenshot의 위치 지정, 클래스 생성할때 가져오기\n",
    "        \n",
    "        #winflg와 lose flag 존재해야 함. 0으로 하는 건 grayscale\n",
    "        self.winFlag = cv2.imread('/home/jnu/Desktop/Reinforce/Royale/screenshot/cr_test/weWin.png', 0)\n",
    "        self.loseFlag = cv2.imread('/home/jnu/Desktop/Reinforce/Royale/screenshot/cr_test/enemyWin.png', 0)\n",
    "        #nocard flag\n",
    "        self.nocardFlag = cv2.imread('/home/jnu/Desktop/Reinforce/Royale/screenshot/test1/nocard.png')\n",
    "        #noElixir flag\n",
    "        self.noelixirFlag = cv2.imread('/home/jnu/Desktop/Reinforce/Royale/screenshot/test1/noElixir.png')\n",
    "        self.startGameFlag = cv2.imread('/home/jnu/Desktop/Reinforce/Royale/screenshot/cr_test/battleStart.png')\n",
    "    \n",
    "    def return_state(self, img):\n",
    "        #스크린 샷을 인자로 받아와서 모델에 넣을 수 있도록 tensor로 변환\n",
    "        tf = transforms.ToTensor()\n",
    "        img_t = tf(img)\n",
    "        img_t = img_t.unsqueeze(0)\n",
    "        #img_t = img_t.permute(1, 0, 2, 3)\n",
    "        \n",
    "        \n",
    "        return img_t\n",
    "    \n",
    "    def check_win(self, img):\n",
    "        #게임이 이겼는지 확인, screenshot을 가져와서 우리가 원하는 크기로 잘라서 확인\n",
    "        #img = np.array(img)\n",
    "        checkFlag1 = np.array(img.crop((225,335,280,365)))\n",
    "        checkFlag1 = cv2.cvtColor(checkFlag1, cv2.COLOR_BGR2GRAY)\n",
    "        win_check=cv2.matchTemplate(checkFlag1,self.winFlag,cv2.TM_CCOEFF_NORMED)\n",
    "        if win_check > 0.8:\n",
    "            return 1\n",
    "        \n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    def check_lose(self, img):\n",
    "        #게임이 졌는지 확인, screenshot을 가져와서 우리가 원하는 크기로 잘라서 확인\n",
    "        #img = np.array(img)\n",
    "        checkFlag2 = np.array(img.crop((225,85,280,115)))\n",
    "        checkFlag2 = cv2.cvtColor(checkFlag2, cv2.COLOR_BGR2GRAY)\n",
    "        lose_check = cv2.matchTemplate(checkFlag2,self.loseFlag,cv2.TM_CCOEFF_NORMED)\n",
    "        if lose_check > 0.8:\n",
    "            return 1\n",
    "        \n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "        \n",
    "    def check_card(self, img):\n",
    "        #카드를 선택하지 않았는지 확인, screenshot을 가져와서 init에 지정된 nocard 이미지와 비교하여 reward 부여\n",
    "        nocard = cv2.cvtColor(self.nocardFlag, cv2.COLOR_BGR2GRAY)\n",
    "        img = np.array(img)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        ratio = cv2.matchTemplate(nocard,img,cv2.TM_CCOEFF_NORMED)\n",
    "        \n",
    "        if(np.max(ratio) > 0.90):\n",
    "            #print(np.max(ratio))\n",
    "            return 1\n",
    "        \n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    def check_elixir(self, img):\n",
    "        noElixir = cv2.cvtColor(self.noelixirFlag, cv2.COLOR_BGR2GRAY)\n",
    "        img = np.array(img)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        ratio = cv2.matchTemplate(noElixir,img,cv2.TM_CCOEFF_NORMED)\n",
    "        \n",
    "        if(np.max(ratio) > 0.90):\n",
    "            #print(np.max(ratio))\n",
    "            return 1\n",
    "        \n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    def checkET1(self, img):\n",
    "        score1 = 0\n",
    "        checkFlag1 = np.array(img.crop((99,135,149,136)))\n",
    "        \n",
    "        for i in range(50):\n",
    "            if(checkFlag1[0][i][0]<=96):\n",
    "                score1 += 1\n",
    "                \n",
    "        score1 = score1 * 2\n",
    "        return score1\n",
    "        \n",
    "    def checkET2(self, img):\n",
    "        score2 = 0\n",
    "        checkFlag2 = np.array(play_screen.crop((356,135,406,136)))\n",
    "        \n",
    "        for i in range(50):\n",
    "            if(checkFlag2[0][i][0]<=96):\n",
    "                score2 += 1\n",
    "                \n",
    "        score2 = score2 * 2\n",
    "        return score2\n",
    "    \n",
    "    def checkGameStart(self, img):\n",
    "        startMessage = cv2.cvtColor(self.startGameFlag, cv2.COLOR_BGR2GRAY)\n",
    "        img = np.array(img)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        ratio = cv2.matchTemplate(startMessage,img,cv2.TM_CCOEFF_NORMED)\n",
    "        if(np.max(ratio) > 0.90):\n",
    "            #print(np.max(ratio))\n",
    "            return 1\n",
    "        \n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    #def checkET3\n",
    "    \n",
    "    #def checkOT1\n",
    "    #def checkOT1\n",
    "    #def checkOT1\n",
    "    \n",
    "    #우리 타워와 상대 타워의 hp를 확인하여 reward 부여\n",
    "    \n",
    "    \n",
    "    def retryGame(self):\n",
    "        pag.click((2860, 875))\n",
    "        time.sleep(2)\n",
    "        pag.click((3070, 185))\n",
    "        time.sleep(1)\n",
    "        pag.click((2920, 385))\n",
    "        time.sleep(0.5)\n",
    "        pag.click((2950, 615))\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5ad6722b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer():\n",
    "    def __init__(self):\n",
    "        self.buffer = collections.deque()\n",
    "        self.batch_size = 5\n",
    "        self.size_limit = 50000\n",
    "        \n",
    "    def put(self, data):\n",
    "        self.buffer.append(data)\n",
    "        if len(self.buffer) > self.size_limit:\n",
    "            self.buffer.popleft()\n",
    "            \n",
    "    def sample(self, n):\n",
    "        print(f\"self.buffer = {len(self.buffer)}\")\n",
    "        return random.sample(self.buffer, n)\n",
    "    \n",
    "    def size(self):\n",
    "        return len(self.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "128c3674",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(q, q_target, memory, gamma, optimizer, batch_size):\n",
    "    for i in range(3):\n",
    "        #print(f\"batch_size = {batch_size}, memory.size = {memory.size()}\")\n",
    "        batch = memory.sample(batch_size)\n",
    "        #print(f\"size = {len(batch[0])}\")\n",
    "        s_lst, a_lst, r_lst, s_prime_lst, done_mask_lst = [], [], [], [], []\n",
    "        \n",
    "        for transition in batch:\n",
    "            s, a, r, s_prime, done_mask = transition\n",
    "            s_lst.append(s)\n",
    "            a_lst.append([a])\n",
    "            r_lst.append([r])\n",
    "            s_prime_lst.append(s_prime)\n",
    "            done_mask_lst.append([done_mask])\n",
    "            \n",
    "        s_lst = torch.stack(s_lst)\n",
    "        s_prime_lst = torch.stack(s_prime_lst)\n",
    "        #print(f\"about s = {type(s_lst)}\")\n",
    "        s, a, r, s_prime, done_mask = s_lst, torch.tensor(a_lst), \\\n",
    "                                    torch.tensor(r_lst), s_prime_lst,\\\n",
    "                                    torch.tensor(done_mask_lst)\n",
    "        \n",
    "        #print(f\"about S = {type(s)}\")\n",
    "        s = s.squeeze()\n",
    "        s_prime = s_prime.squeeze()\n",
    "        q_out = q(s)\n",
    "        q_a = q_out.gather(1, a)\n",
    "        max_q_prime = q_target(s_prime).max(1)[0].unsqueeze(1)\n",
    "        target = r + gamma * max_q_prime * done_mask\n",
    "        loss = F.smooth_l1_loss(target, q_a)\n",
    "        print(f\"loss = {loss}\")\n",
    "        optimizer.zero_grad()\n",
    "        print(\"we got the end1\")\n",
    "        loss.backward()\n",
    "        print(\"we got the end2\")\n",
    "        optimizer.step()\n",
    "        print(\"we got the end3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a9b4f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b5bbc9f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1688297143.3299239\n",
      "1688297143.331164\n",
      "1688297144.687626\n",
      "1688297146.067879\n",
      "1688297146.2912078\n",
      "1688297146.2912366\n",
      "1688297146.3162832\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "env = ENV()\n",
    "t2 = time.time()\n",
    "q = DQN()\n",
    "t3 = time.time()\n",
    "q_target = DQN()\n",
    "t4 = time.time()\n",
    "q_target.load_state_dict(q.state_dict())\n",
    "t5 = time.time()\n",
    "memory = ReplayBuffer()\n",
    "t6 = time.time()\n",
    "avg_t = 0\n",
    "gamma = 0.98\n",
    "batch_size = 5\n",
    "optimizer = optim.Adam(q.parameters(), lr = 0.0005)\n",
    "t7= time.time()\n",
    "\n",
    "middleBuffer = []\n",
    "\n",
    "print(t1)\n",
    "print(t2)\n",
    "print(t3)\n",
    "print(t4)\n",
    "print(t5)\n",
    "print(t6)\n",
    "print(t7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c4d2351",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game start\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m(env\u001b[38;5;241m.\u001b[39mcheckGameStart(img)):\n\u001b[1;32m     24\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgame start\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 25\u001b[0m         \u001b[43mtime\u001b[49m\u001b[38;5;241m.\u001b[39mdelay(\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m     26\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     29\u001b[0m epsilon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m0.01\u001b[39m \u001b[38;5;241m*\u001b[39m (n_epi\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m200\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'time' is not defined"
     ]
    }
   ],
   "source": [
    "n_epi = 0\n",
    "done = 0\n",
    "train_time = 0\n",
    "while(1):\n",
    "    #s 변수 설정\n",
    "    img = pag.screenshot(region = (2605, 100, 510, 900))\n",
    "    img_t = env.return_state(img)\n",
    "    s = img_t\n",
    "    \n",
    "    #reward 초기화\n",
    "    reward = 0\n",
    "    #enemy tower score / score1 = left, score2 = right\n",
    "    score1 = 100\n",
    "    score2 = 100\n",
    "    \n",
    "    while(1):\n",
    "        #epsilon 조절\n",
    "        while(1):\n",
    "            #스크린샷 찍기\n",
    "            img = pag.screenshot(region = (2605, 100, 510, 900))\n",
    "\n",
    "            \n",
    "            if(env.checkGameStart(img)):\n",
    "                print(\"game start\")\n",
    "                time.delay(3)\n",
    "                break\n",
    "            \n",
    "            \n",
    "        epsilon = max(0.1, 0.5 - 0.01 * (n_epi/200))\n",
    "        n_epi += 1\n",
    "        reward -= 1\n",
    "        \n",
    "        #스크린샷 찍기\n",
    "        img = pag.screenshot(region = (2605, 100, 510, 900))\n",
    "        \n",
    "        #모델에 넣기 위해 tensor로 변환\n",
    "        img_t = env.return_state(img)\n",
    "        s_prime = img_t\n",
    "        a = q.sample_action(img_t, epsilon)\n",
    "        \n",
    "        #화면 클릭\n",
    "        #pag.click(action_list[a][0], action_list[a][1])\n",
    "        \n",
    "        #승리 확인\n",
    "        if(env.check_win(img)):\n",
    "            print(\"win\")\n",
    "            reward += 10000\n",
    "            done = 1\n",
    "            \n",
    "\n",
    "        #패배 확인\n",
    "        elif(env.check_lose(img)):\n",
    "            print(\"lose\")\n",
    "            reward -= 10000\n",
    "            done = 1\n",
    "            \n",
    "\n",
    "        #no card확인\n",
    "        if(env.check_card(img)):\n",
    "            reward -= 100\n",
    "            print(\"no card\")\n",
    "            \n",
    "        #no elixir확인\n",
    "        if(env.check_elixir(img)):\n",
    "            reward -= 100\n",
    "            print(\"no Elixir\")\n",
    "            \n",
    "        #enemy tower reward calculate\n",
    "        score1_now = env.checkET1(img)\n",
    "        score2_now = env.checkET1(img)\n",
    "        #print(f\"score1 = {score1}, score1_now = {score1_now}\")\n",
    "        #print(f\"score2 = {score2}, score2_now = {score2_now}\")\n",
    "        if(score1_now < score1):\n",
    "            \n",
    "            reward += 10 * (score1 - score1_now)\n",
    "            score1 = score1_now\n",
    "        \n",
    "        if(score2_now < score2):\n",
    "            \n",
    "            reward += 10 * (score2 - score2_now)\n",
    "            score2 = score2_now\n",
    "        \n",
    "        \n",
    "        middleBuffer.append((s, a, reward, s_prime, done))\n",
    "        print('action =',action_list_name[a], '    index = ', action_list[a][0], action_list[a][1], '    reward = ', reward)\n",
    "        \n",
    "        s = s_prime\n",
    "        \n",
    "        if done == 1:\n",
    "            break\n",
    "            \n",
    "#         #memory size 2000넘으면 학습 시작\n",
    "#         if len(middleBuffer) >= 20:\n",
    "#             for i in range(len(middleBuffer)):\n",
    "#                 memory.put(middleBuffer[i])\n",
    "\n",
    "#             print(len(memory.buffer))\n",
    "#             print(\"========================\")\n",
    "#             #print(middleBuffer.size())\n",
    "#             middleBuffer = []\n",
    "\n",
    "\n",
    "#             train(q, q_target, memory, gamma, optimizer, batch_size)\n",
    "#             train_time += 1\n",
    "#             print(f\"train time = {train_time}\")\n",
    "\n",
    "#         if n_epi%20 == 0and n_epi!=0:\n",
    "#             q_target.load_state_dict(q.state_dict())\n",
    "#             print(f\"epi = {n_epi}, buffer size = {memory.size()}, epsilon = {epsilon}\") \n",
    "\n",
    "    #reak        \n",
    "    env.retryGame()\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a978f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
