{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "970e56a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import collections\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pyautogui as pag\n",
    "import PIL\n",
    "import torchvision.transforms as transforms\n",
    "import cv2\n",
    "import numpy as np\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d1d1fbe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-01 16:20:53.391713: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "writer = SummaryWriter()\n",
    "train_time = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e94ef1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DQN 모델 정의\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self,num_actions):\n",
    "        super(DQN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(nn.Conv2d(3, 16, 3, stride=2, padding=1),\n",
    "                                   nn.BatchNorm2d(16),\n",
    "                                   nn.ReLU(inplace=True))\n",
    "        self.conv2 = nn.Sequential(nn.Conv2d(16, 64, 3, stride=2, padding=1),\n",
    "                                   nn.BatchNorm2d(64),\n",
    "                                   nn.ReLU(inplace=True))\n",
    "        self.conv3 = nn.Sequential(nn.Conv2d(64, 256, 3, stride=2, padding=1),\n",
    "                                   nn.BatchNorm2d(256),\n",
    "                                   nn.ReLU(inplace=True))\n",
    "        self.actor_linear = nn.Sequential(nn.Linear(1851392, 256),\n",
    "                                          nn.ReLU(inplace=True),\n",
    "                                          nn.Linear(256,num_actions))\n",
    "\n",
    "    def forward(self, x): #각 action에 대한 가치를 softmax를 거쳐서 확률로 출력\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        \n",
    "        x = self.actor_linear(x.reshape(x.size(0), -1))\n",
    "        return x\n",
    "    \n",
    "    def sample_action(self, obs, epsilon):\n",
    "        out = self.forward(obs)\n",
    "        coin = random.random()\n",
    "        if coin < epsilon:\n",
    "            return random.randint(0, 10)\n",
    "        else:\n",
    "            return out.argmax().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0ffc38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_list = [[2720, 550], [2860, 550], [3000, 550], [2720 ,660], [2860, 660], [3000, 660], [2765, 900], [2855, 900], [2950, 900], [3055, 900], [-1, -1]]\n",
    "#action list 정의. action list는 6개의 필드 위치와 4개의 카드 위치 그리고 한개의 아무것도 안하는 리워드를 주었다.\n",
    "action_list_name = {0:'left top', 1:'center top', 2:'right top', 3:'right bottom', 4:'center bottom', 5:'center right', 6:'card 1', 7:'card 2', 8:'card 3', 9:'card 4', 10:'rest action'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b130d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ENV():\n",
    "    def __init__(self):\n",
    "        #screenshot의 위치 지정, 클래스 생성할때 가져오기\n",
    "        \n",
    "        #winflg와 lose flag 존재해야 함. 0으로 하는 건 grayscale\n",
    "        self.winFlag = cv2.imread('/home/jnu/Desktop/Reinforce/Royale/screenshot/cr_test/weWin.png', 0)\n",
    "        self.loseFlag = cv2.imread('/home/jnu/Desktop/Reinforce/Royale/screenshot/cr_test/enemyWin.png', 0)\n",
    "        #nocard flag\n",
    "        self.nocardFlag = cv2.imread('/home/jnu/Desktop/Reinforce/Royale/screenshot/test1/nocard.png')\n",
    "        #noElixir flag\n",
    "        self.noelixirFlag = cv2.imread('/home/jnu/Desktop/Reinforce/Royale/screenshot/test1/noElixir.png')\n",
    "    \n",
    "    def return_state(self, img):\n",
    "        #스크린 샷을 인자로 받아와서 모델에 넣을 수 있도록 tensor로 변환\n",
    "        tf = transforms.ToTensor()\n",
    "        img_t = tf(img)\n",
    "        img_t = img_t.unsqueeze(0)\n",
    "        #img_t = img_t.permute(1, 0, 2, 3)\n",
    "        \n",
    "        \n",
    "        return img_t\n",
    "    \n",
    "    def check_win(self, img):\n",
    "        #게임이 이겼는지 확인, screenshot을 가져와서 우리가 원하는 크기로 잘라서 확인\n",
    "        #img = np.array(img)\n",
    "        checkFlag1 = np.array(img.crop((225,335,280,365)))\n",
    "        checkFlag1 = cv2.cvtColor(checkFlag1, cv2.COLOR_BGR2GRAY)\n",
    "        win_check = cv2.matchTemplate(checkFlag1,self.winFlag,cv2.TM_CCOEFF_NORMED)\n",
    "        if win_check > 0.8:\n",
    "            return 1\n",
    "        \n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    def check_lose(self, img):\n",
    "        #게임이 졌는지 확인, screenshot을 가져와서 우리가 원하는 크기로 잘라서 확인\n",
    "        #img = np.array(img)\n",
    "        checkFlag2 = np.array(img.crop((225,85,280,115)))\n",
    "        checkFlag2 = cv2.cvtColor(checkFlag2, cv2.COLOR_BGR2GRAY)\n",
    "        lose_check = cv2.matchTemplate(checkFlag2,self.loseFlag,cv2.TM_CCOEFF_NORMED)\n",
    "        if lose_check > 0.8:\n",
    "            return 1\n",
    "        \n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "        \n",
    "    def check_card(self, img):\n",
    "        #카드를 선택하지 않았는지 확인, screenshot을 가져와서 init에 지정된 nocard 이미지와 비교하여 reward 부여\n",
    "        nocard = cv2.cvtColor(self.nocardFlag, cv2.COLOR_BGR2GRAY)\n",
    "        img = np.array(img)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        ratio = cv2.matchTemplate(nocard,img,cv2.TM_CCOEFF_NORMED)\n",
    "        \n",
    "        if(np.max(ratio) > 0.90):\n",
    "            #print(np.max(ratio))\n",
    "            return 1\n",
    "        \n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    def check_elixir(self, img):\n",
    "        noElixir = cv2.cvtColor(self.noelixirFlag, cv2.COLOR_BGR2GRAY)\n",
    "        img = np.array(img)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        ratio = cv2.matchTemplate(noElixir,img,cv2.TM_CCOEFF_NORMED)\n",
    "        \n",
    "        if(np.max(ratio) > 0.90):\n",
    "            #print(np.max(ratio))\n",
    "            return 1\n",
    "        \n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    def checkET1(self, img):\n",
    "        score1 = 0\n",
    "        checkFlag1 = np.array(img.crop((99,135,149,136)))\n",
    "        \n",
    "        for i in range(50):\n",
    "            if(checkFlag1[0][i][0]<=96):\n",
    "                score1 += 1\n",
    "                \n",
    "        score1 = score1 * 2\n",
    "        return score1\n",
    "        \n",
    "    def checkET2(self, img):\n",
    "        score2 = 0\n",
    "        checkFlag2 = np.array(play_screen.crop((356,135,406,136)))\n",
    "        \n",
    "        for i in range(50):\n",
    "            if(checkFlag2[0][i][0]<=96):\n",
    "                score2 += 1\n",
    "                \n",
    "        score2 = score2 * 2\n",
    "        return score2\n",
    "        \n",
    "    #def checkET3\n",
    "    \n",
    "    #def checkOT1\n",
    "    #def checkOT1\n",
    "    #def checkOT1\n",
    "    \n",
    "    #우리 타워와 상대 타워의 hp를 확인하여 reward 부여\n",
    "    \n",
    "    \n",
    "    def retryGame(self):\n",
    "        pag.click((2860, 875))\n",
    "        time.sleep(2)\n",
    "        pag.click((3070, 185))\n",
    "        time.sleep(1)\n",
    "        pag.click((2920, 385))\n",
    "        time.sleep(0.5)\n",
    "        pag.click((2950, 615))\n",
    "        pass\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ad6722b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer():\n",
    "    def __init__(self):\n",
    "        self.buffer = collections.deque()\n",
    "        self.batch_size = 5\n",
    "        self.size_limit = 50000\n",
    "        \n",
    "    def put(self, data):\n",
    "        self.buffer.append(data)\n",
    "        if len(self.buffer) > self.size_limit:\n",
    "            self.buffer.popleft()\n",
    "            \n",
    "    def sample(self, n):\n",
    "        print(f\"self.buffer = {len(self.buffer)}\")\n",
    "        return random.sample(self.buffer, n)\n",
    "    \n",
    "    def size(self):\n",
    "        return len(self.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "128c3674",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(q, q_target, memory, gamma, optimizer, batch_size):\n",
    "    global train_time\n",
    "    for i in range(3):\n",
    "        #print(f\"batch_size = {batch_size}, memory.size = {memory.size()}\")\n",
    "        batch = memory.sample(batch_size)\n",
    "        #print(f\"size = {len(batch[0])}\")\n",
    "        s_lst, a_lst, r_lst, s_prime_lst, done_mask_lst = [], [], [], [], []\n",
    "        \n",
    "        for transition in batch:\n",
    "            s, a, r, s_prime, done_mask = transition\n",
    "            s_lst.append(s)\n",
    "            a_lst.append([a])\n",
    "            r_lst.append([r])\n",
    "            s_prime_lst.append(s_prime)\n",
    "            done_mask_lst.append([done_mask])\n",
    "            \n",
    "        s_lst = torch.stack(s_lst)\n",
    "        s_prime_lst = torch.stack(s_prime_lst)\n",
    "        #print(f\"about s = {type(s_lst)}\")\n",
    "        s, a, r, s_prime, done_mask = s_lst, torch.tensor(a_lst), \\\n",
    "                                    torch.tensor(r_lst), s_prime_lst,\\\n",
    "                                    torch.tensor(done_mask_lst)\n",
    "        \n",
    "        #print(f\"about S = {type(s)}\")\n",
    "        s = s.squeeze()\n",
    "        s_prime = s_prime.squeeze()\n",
    "        q_out = q(s)\n",
    "        q_a = q_out.gather(1, a)\n",
    "        max_q_prime = q_target(s_prime).max(1)[0].unsqueeze(1)\n",
    "        target = r + gamma * max_q_prime * done_mask\n",
    "        loss = F.smooth_l1_loss(target, q_a)\n",
    "        print(f\"loss = {loss}\")\n",
    "        \n",
    "        \n",
    "        train_time += 1\n",
    "        writer.add_scalar(\"Loss/train\", loss, train_time)\n",
    "        writer.flush()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        print(\"we got the end1\")\n",
    "        loss.backward()\n",
    "        print(\"we got the end2\")\n",
    "        optimizer.step()\n",
    "        print(\"we got the end3\")\n",
    "        \n",
    "        \n",
    "        if train_time >= 5:\n",
    "            \n",
    "            writer.close()\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5bbc9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = ENV()\n",
    "q = DQN(len(action_list))\n",
    "q_target = DQN(len(action_list))\n",
    "q_target.load_state_dict(q.state_dict())\n",
    "memory = ReplayBuffer()\n",
    "\n",
    "avg_t = 0\n",
    "gamma = 0.98\n",
    "batch_size = 5\n",
    "optimizer = optim.RMSprop(q.parameters(), lr = 0.0005)\n",
    "\n",
    "middleBuffer = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c4d2351",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action = card 4     index =  3055 900     reward =  1439\n",
      "action = center top     index =  2860 550     reward =  1438\n",
      "action = card 1     index =  2765 900     reward =  1437\n",
      "action = right bottom     index =  2720 660     reward =  1436\n",
      "action = right top     index =  3000 550     reward =  1435\n",
      "action = card 4     index =  3055 900     reward =  1434\n",
      "action = card 4     index =  3055 900     reward =  1433\n",
      "action = card 4     index =  3055 900     reward =  1432\n",
      "action = card 4     index =  3055 900     reward =  1431\n",
      "action = right top     index =  3000 550     reward =  1430\n",
      "action = card 4     index =  3055 900     reward =  1429\n",
      "action = card 4     index =  3055 900     reward =  1428\n",
      "action = center top     index =  2860 550     reward =  1427\n",
      "action = card 2     index =  2855 900     reward =  1426\n",
      "action = card 4     index =  3055 900     reward =  1425\n",
      "action = rest action     index =  -1 -1     reward =  1424\n",
      "action = center bottom     index =  2860 660     reward =  1423\n",
      "action = card 4     index =  3055 900     reward =  1422\n",
      "action = rest action     index =  -1 -1     reward =  1421\n",
      "action = card 4     index =  3055 900     reward =  1420\n",
      "20\n",
      "========================\n",
      "self.buffer = 20\n",
      "loss = 1429.6898193359375\n",
      "we got the end1\n",
      "we got the end2\n",
      "we got the end3\n",
      "self.buffer = 20\n",
      "loss = 3314.076904296875\n",
      "we got the end1\n",
      "we got the end2\n",
      "we got the end3\n",
      "self.buffer = 20\n",
      "loss = 2436.23095703125\n",
      "we got the end1\n",
      "we got the end2\n",
      "we got the end3\n",
      "train time = 3\n",
      "epi = 20, buffer size = 20, epsilon = 0.49905\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m reward \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m#스크린샷 찍기\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mpag\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscreenshot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mregion\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2605\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m510\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m900\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m#모델에 넣기 위해 tensor로 변환\u001b[39;00m\n\u001b[1;32m     25\u001b[0m img_t \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mreturn_state(img)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_book/lib/python3.9/site-packages/pyscreeze/__init__.py:505\u001b[0m, in \u001b[0;36m_screenshot_linux\u001b[0;34m(imageFilename, region)\u001b[0m\n\u001b[1;32m    503\u001b[0m     tmpFilename \u001b[38;5;241m=\u001b[39m imageFilename\n\u001b[1;32m    504\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m scrotExists:\n\u001b[0;32m--> 505\u001b[0m     \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mscrot\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m-z\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtmpFilename\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    506\u001b[0m     im \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(tmpFilename)\n\u001b[1;32m    508\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m region \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_book/lib/python3.9/subprocess.py:349\u001b[0m, in \u001b[0;36mcall\u001b[0;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall\u001b[39m(\u001b[38;5;241m*\u001b[39mpopenargs, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    342\u001b[0m     \u001b[38;5;124;03m\"\"\"Run command with arguments.  Wait for command to complete or\u001b[39;00m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;124;03m    timeout, then return the returncode attribute.\u001b[39;00m\n\u001b[1;32m    344\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;124;03m    retcode = call([\"ls\", \"-l\"])\u001b[39;00m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 349\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpopenargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m p:\n\u001b[1;32m    350\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    351\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m p\u001b[38;5;241m.\u001b[39mwait(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_book/lib/python3.9/subprocess.py:947\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask)\u001b[0m\n\u001b[1;32m    943\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_mode:\n\u001b[1;32m    944\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[1;32m    945\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m--> 947\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    948\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    949\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    950\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    951\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    952\u001b[0m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    953\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    954\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    957\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[1;32m    958\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdin, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr)):\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_book/lib/python3.9/subprocess.py:1775\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session)\u001b[0m\n\u001b[1;32m   1773\u001b[0m errpipe_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbytearray\u001b[39m()\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1775\u001b[0m     part \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43merrpipe_read\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1776\u001b[0m     errpipe_data \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m part\n\u001b[1;32m   1777\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m part \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(errpipe_data) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m50000\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_epi = 0\n",
    "done = 0\n",
    "while(1):\n",
    "    #s 변수 설정\n",
    "    img = pag.screenshot(region = (2605, 100, 510, 900))\n",
    "    img_t = env.return_state(img)\n",
    "    s = img_t\n",
    "    \n",
    "    #reward 초기화\n",
    "    reward = 0\n",
    "    #enemy tower score / score1 = left, score2 = right\n",
    "    score1 = 100\n",
    "    score2 = 100\n",
    "    \n",
    "    while(1):\n",
    "        #epsilon 조절\n",
    "        epsilon = max(0.1, 0.5 - 0.01 * (n_epi/200))\n",
    "        n_epi += 1\n",
    "        reward -= 1\n",
    "        \n",
    "        #스크린샷 찍기\n",
    "        img = pag.screenshot(region = (2605, 100, 510, 900))\n",
    "        \n",
    "        #모델에 넣기 위해 tensor로 변환\n",
    "        img_t = env.return_state(img)\n",
    "        s_prime = img_t\n",
    "        a = q.sample_action(img_t, epsilon)\n",
    "        \n",
    "        #화면 클릭\n",
    "        #pag.click(action_list[a][0], action_list[a][1])\n",
    "        \n",
    "        #승리 확인\n",
    "        if(env.check_win(img)):\n",
    "            print(\"win\")\n",
    "            reward += 10000\n",
    "            done = 1\n",
    "            \n",
    "\n",
    "        #패배 확인\n",
    "        elif(env.check_lose(img)):\n",
    "            print(\"lose\")\n",
    "            reward -= 10000\n",
    "            done = 1\n",
    "            \n",
    "\n",
    "        #no card확인\n",
    "        if(env.check_card(img)):\n",
    "            reward -= 100\n",
    "            print(\"no card\")\n",
    "            \n",
    "        #no elixir확인\n",
    "        if(env.check_elixir(img)):\n",
    "            reward -= 100\n",
    "            print(\"no Elixir\")\n",
    "            \n",
    "        #enemy tower reward calculate\n",
    "        score1_now = env.checkET1(img)\n",
    "        score2_now = env.checkET1(img)\n",
    "        #print(f\"score1 = {score1}, score1_now = {score1_now}\")\n",
    "        #print(f\"score2 = {score2}, score2_now = {score2_now}\")\n",
    "        if(score1_now < score1):\n",
    "            \n",
    "            reward += 10 * (score1 - score1_now)\n",
    "            score1 = score1_now\n",
    "        \n",
    "        if(score2_now < score2):\n",
    "            \n",
    "            reward += 10 * (score2 - score2_now)\n",
    "            score2 = score2_now\n",
    "        \n",
    "        \n",
    "        middleBuffer.append((s, a, reward, s_prime, done))\n",
    "        print('action =',action_list_name[a], '    index = ', action_list[a][0], action_list[a][1], '    reward = ', reward)\n",
    "        \n",
    "        s = s_prime\n",
    "        \n",
    "        if done == 1:\n",
    "            break\n",
    "            \n",
    "        #memory size 2000넘으면 학습 시작\n",
    "        if len(middleBuffer) >= 20:\n",
    "            for i in range(len(middleBuffer)):\n",
    "                memory.put(middleBuffer[i])\n",
    "\n",
    "            print(len(memory.buffer))\n",
    "            print(\"========================\")\n",
    "            #print(middleBuffer.size())\n",
    "            middleBuffer = []\n",
    "\n",
    "\n",
    "            train(q, q_target, memory, gamma, optimizer, batch_size)\n",
    "            \n",
    "            print(f\"train time = {train_time}\")\n",
    "            \n",
    "        \n",
    "\n",
    "        if n_epi%20 == 0and n_epi!=0:\n",
    "            q_target.load_state_dict(q.state_dict())\n",
    "            print(f\"epi = {n_epi}, buffer size = {memory.size()}, epsilon = {epsilon}\") \n",
    "\n",
    "    #reak        \n",
    "    env.retryGame()\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a978f7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19b4afb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torchsummaryX import summary\n",
    "summary(q,torch.zeros(1,3,900,510))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c3f9d1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "q.conv3[0].weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a99652",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
