# Reinforcement_ClashRoyale

## 개요
본 프로젝트는 클래시로얄 게임을 강화학습으로 풀어보고자 하였습니다. 이상적인 학습은 이루어지지 않았지만 강화학습을 위한 ENV 설정과 Reward 체계 구현 등에서 의미를 지니고 있습니다.

## 클래시 로얄이란?
클래시 로얄은 카드 수집형 실시간 타워 디펜스 게임입니다. 사용자는 카드를 선택하여 소환할 수 있으며 정해진 시간안에 상대 킹 타워를 파괴하면 승리합니다. 카드 소환에는 엘릭서라는 자원이 필요하며 카드 덱의 구성에 따라 다양한 전략이 가능합니다.

## 시작 전
ubuntu 20.04 위에서 개발되었습니다. 클래시 로얄 게임이 ubuntu에서 돌아가지 못하기 때문에 vmware로 windows를 설치하고 그 위에 blue stack을 설치하여 사용합니다.
ubuntu에서 몇가지 에뮬레이터를 설치하여 클래시 로얄을 돌려보려고 하였으나 성공하지 못하였고(개발 초기 단계에서 시간이 오래 지나 정확한 이유 잊어버림) <br>
ubuntu에서 vmware를 설치하고 그 다음 blue stack을 설치하여 게임을 플레이 하였습니다.<br>
arm 기반 architecture가 문제가 되어서 super cell에서 만든 게임을 돌리지 못했던 것으로 기억합니다.<br>
해결 방법이 있으면 알려주세요.

## ENV
강화학습 ENV는 다음과 같은 기능으로 구현되어 있습니다.

## Action
Action은 카드를 선택할 수 있는 4가지 선택지와 map을 () * () 로 구분한 ()가지 선택지가 존재하며 총 () 개의 action을 가지고 있습니다.

## Agent
Agent는 state를 입력받아 Actiondmf 결정합니다.
모델 출력단에서 softmax를 적용하여 다음 선택지를 classification 문제로 해결할 수 있습니다.
모델은 다음과 같은 구조를 사용하였습니다.

## state
state는 게임에 영향을 주는 부분을 잘라서 사용합니다. size는 ()입니다.
사용자 설정에 따라 resize, grayscale, framestack을 적용하여 사용할 수 있습니다.

## 시연 영상

