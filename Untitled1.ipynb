{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "645030f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import collections\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pyautogui as pag\n",
    "import PIL\n",
    "import torchvision.transforms as transforms\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3131aa82",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN_test2(nn.Module):\n",
    "    def __init__(self, n_action):\n",
    "        super(DQN_test2, self).__init__()\n",
    "        self.conv1 = nn.Sequential(nn.Conv2d(3, 16, kernel_size=3, padding=1, stride=2),\n",
    "                                nn.BatchNorm2d(16),\n",
    "                                nn.ReLU(inplace=True))\n",
    "        self.conv2 = nn.Sequential(nn.Conv2d(16, 64, kernel_size=3, padding=1, stride=2),\n",
    "                                nn.BatchNorm2d(64),\n",
    "                                nn.ReLU(inplace=True))\n",
    "        self.conv3 = nn.Sequential(nn.Conv2d(64, 256, kernel_size=3, padding=1, stride=2),\n",
    "                                nn.BatchNorm2d(256),\n",
    "                                nn.ReLU(inplace=True))\n",
    "        self.conv4 = nn.Sequential(nn.Conv2d(256, 512, kernel_size=3, padding=1, stride=2),\n",
    "                                nn.BatchNorm2d(512),\n",
    "                                nn.ReLU(inplace=True))\n",
    "        self.actor_linear = nn.Sequential(nn.Linear(933888, 256),\n",
    "                                          nn.ReLU(inplace=True),\n",
    "                                          nn.Linear(256,10))\n",
    "        \n",
    "    def forward(self, x): #각 action에 대한 가치출력\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.actor_linear(x.reshape(x.size(0), -1))\n",
    "        return x\n",
    "    \n",
    "    def sample_action(self, obs, epsilon):\n",
    "        out = self.forward(obs)\n",
    "        coin = random.random()\n",
    "        if coin < epsilon:\n",
    "            return random.randint(0, 1)\n",
    "        else:\n",
    "            return out.argmax().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbe33538",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_list2 = [[2720, 550], [2860, 550], [3000, 550], [2720 ,660], [2860, 660], [3000, 660], [2765, 900], [2855, 900], [2950, 900], [3055, 900], [-1, -1]]\n",
    "#앞의 6개 값은 화면, 뒤의 4개는 카드\n",
    "#-1 action은 기다리라는 action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d675ddaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer():\n",
    "    def __init__(self):\n",
    "        self.buffer = collections.deque()\n",
    "        self.batch_size = 32\n",
    "        self.size_limit = 50000\n",
    "        \n",
    "    def put(self, data):\n",
    "        self.buffer.append(data)\n",
    "        if len(self.buffer) > self.size_limit:\n",
    "            self.buffer.popleft()\n",
    "        \n",
    "    def sample(self, n):\n",
    "        return random.sample(self.buffer, n)\n",
    "    \n",
    "    def size(self):\n",
    "        return len(self.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "19f467a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ENV():\n",
    "    def __init__(self, actions):\n",
    "        self.actions = actions\n",
    "    \n",
    "    def obs(self):\n",
    "        img = pag.screenshot(region=(2605, 100, 510, 900))\n",
    "        tf = transforms.ToTensor()\n",
    "        img_t = tf(img)\n",
    "        img_t = img_t.unsqueeze(0)\n",
    "        return img_t\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98eaf139",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(q, q_target, memory, gamma, optimizer, batch_size):\n",
    "    for i in range(10):\n",
    "        batch = memory.sample(batch_size)\n",
    "        s_lst, a_lst, r_lst, s_prime_lst, done_mask_lst = [], [], [], [], []\n",
    "        \n",
    "        for transition in batch:\n",
    "            s, a, r, s_prime, done_mask = transition\n",
    "            #s_prime을 꺼내려면 찍은 사진 다음 단계의 이미지가 필요.\n",
    "            s_lst.append(s)\n",
    "            a_lst.append([a])\n",
    "            r_lst.append([r])\n",
    "            s_prime_lst.append(s_prime)\n",
    "            done_mask_lst.append([done_mask])\n",
    "            \n",
    "        s, a, r, s_prime, done_mask = torch.tensor(S_lst, dtype = torch.float), torch.tensor(a_lst),\\\n",
    "                                    torch.tensor(r_lst), torch.tensor(s_prime_lst, dtype = torch.float),\\\n",
    "                                    torch.tensor(done_mask_list)\n",
    "        q_out = q(s)\n",
    "        q_A = q_out.gather(1, a)\n",
    "        max_q_prime = q_target(S_prime).max(1)[0].unsqueeze(1)\n",
    "        target = r + gamma * max_q_prime * done_mask\n",
    "        loss = F.smooth_l1_loss(target, q_a)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f29d461b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = DQN_test2(len(action_list2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e24c1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    q = DQN_test2(len(action_list2))\n",
    "    q_target = DQN_test2(len(action_list2))\n",
    "    q_target.load_state_dict(q.state_dict())\n",
    "    gamma         = 0.98\n",
    "    buffer_limit  = 50000\n",
    "    batch_size    = 24\n",
    "    optimizer = optim.Adam(q.parameters(), lr = 0.0005)\n",
    "    memory = ReplayBuffer()\n",
    "    env = ENV(action_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e67ca092",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "23674b49",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 2720 660\n",
      "3 2720 660\n",
      "3 2720 660\n",
      "3 2720 660\n",
      "3 2720 660\n",
      "3 2720 660\n",
      "3 2720 660\n",
      "3 2720 660\n",
      "3 2720 660\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'random' has no attribute 'randin'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m3600\u001b[39m):\n\u001b[1;32m      8\u001b[0m     img_t \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mobs()\n\u001b[0;32m----> 9\u001b[0m     a \u001b[38;5;241m=\u001b[39m \u001b[43mq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m#best_action = torch.argmax(model(img_t))\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m#plt.imshow(img)\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(a, action_list2[a][\u001b[38;5;241m0\u001b[39m], action_list2[a][\u001b[38;5;241m1\u001b[39m])\n",
      "Cell \u001b[0;32mIn[3], line 32\u001b[0m, in \u001b[0;36mDQN_test2.sample_action\u001b[0;34m(self, obs, epsilon)\u001b[0m\n\u001b[1;32m     30\u001b[0m coin \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mrandom()\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m coin \u001b[38;5;241m<\u001b[39m epsilon:\n\u001b[0;32m---> 32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandin\u001b[49m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\u001b[38;5;241m.\u001b[39margmax()\u001b[38;5;241m.\u001b[39mitem()\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'random' has no attribute 'randin'"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output \n",
    "env = ENV(action_list2)\n",
    "q = DQN_test2(len(action_list2))\n",
    "for n_epi in range(100000):\n",
    "    epsilon = max(0.01, 0.08 - 0.01 * (n_epi/200))\n",
    "    \n",
    "    for t in range(3600):\n",
    "        img_t = env.obs()\n",
    "        a = q.sample_action(img_t, epsilon)\n",
    "        \n",
    "        \n",
    "        #best_action = torch.argmax(model(img_t))\n",
    "\n",
    "        #plt.imshow(img)\n",
    "\n",
    "        print(a, action_list2[a][0], action_list2[a][1])\n",
    "        pag.moveTo(action_list2[a][0], action_list2[a][1])\n",
    "        pag.click()\n",
    "        time.sleep(0.5)\n",
    "        #clear_output()\n",
    "        #pag.click 넣기\n",
    "    \n",
    "    if memory.size() > 2000:\n",
    "        train(q, q_target, memory, gamma, optimizer, batch_size)\n",
    "        \n",
    "    if n_epi%20==0 and n_epi!=0:\n",
    "        q_target.load_state_dict(q.state_dict())\n",
    "        print(f'episode = {n_epi}, buffer size = {memory_size()}, epsilon = {epsilon} *100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9c4ac6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
